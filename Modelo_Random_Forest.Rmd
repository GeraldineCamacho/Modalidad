---
title: "Random Forest"
author: "Yilber Alejandro Erazo Bolaños"
date: "11/2/2021"
output: 
    bookdown: html_document2:
      fig_caption: true
      toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, fig.align = "center")
```

librería
```{r}
#install.packages("ranger")
#install.packages("tidymodels")
library(tidymodels)
library(knitr)
```


# Modelo Random Forest 

## Preprocesamiento de los datos

Lectura de los datos
```{r}
indicadores_gen <- read.csv("indicadores_BD.csv")
```

Eliminar columnas que no son necesarias
```{r}
indicadores_gen$X <- NULL
indicadores_gen$cod_entidad <- NULL #porque hay muy pccos datos de cada municipio
indicadores_gen$nit_entidad <- NULL
indicadores_gen$cod_departamento <- NULL #porque ya se tiene el ombre del departamento
indicadores_gen$municipio_entidad <- NULL #porque hay muy pocos datos de cada municipio
indicadores_gen$depto_mun <- NULL #porque hay muy pocos datos de cada municipio

#para volver a correr el modelo porque con esta columna genera error 
indicadores_gen$nombre_entidad <- NULL

#pasar a factor las nominales a ver si funciona el modelo
#indicadores_gen$nombre_entidad <- as.factor(indicadores_gen$nombre_entidad)
indicadores_gen$orden_entidad <- as.factor(indicadores_gen$orden_entidad)
indicadores_gen$departamento_entidad <- as.factor(indicadores_gen$departamento_entidad)
```

División de los datos en train y test
```{r}
set.seed(123)
indicadores_gen_split <- initial_split(indicadores_gen, strata = perc_contr_directa_num)
indicadores_gen_train <- training(indicadores_gen_split)
indicadores_gen_test <- testing(indicadores_gen_split)
```

Procesamiento y preparación de variables
```{r}
indicadores_gen_rec <- recipe(perc_contr_directa_num ~ ., data = indicadores_gen) %>% 
  #update_role(nombre_entidad, new_role = "ID") %>% 
  step_normalize(all_numeric(), -perc_contr_directa_num) %>% 
  step_dummy(all_nominal(), one_hot = TRUE)

indicadores_gen_rec
```

El objeto 'indicadores_gen_rec' es una rutina de preprocesamiento que se puede aplicar a los datos de train y test.
```{r}
indicadores_gen_train_prep <- indicadores_gen_rec %>% 
  prep(indicadores_gen_train) %>% 
  juice()

head(indicadores_gen_train_prep)
```

## Configurar el modelo por regresión
La librería a usar es 'Parsnip'que ofrece una interfaz unificada para la gran variedad de modelos de machine learning que existen en R. Esto significa que solo tiene que utilizar una forma estandar para configurar un modelo, y puede usar esta configuración diferentes tipos de modelos: Módelo Lineal, Ridge, Lasso, Random Forest, Regresión Logística, Arboles, Support Vector Machine, entre otros.
```{r}
indicadores_gen_rf <- rand_forest() %>% 
  set_args(mtry = tune(),
           trees = tune()) %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("regression")

indicadores_gen_rf %>% translate()
```
## Definir el workflow

El flujo de trabajo permite integrar todas las tareas que se estan desarrollando para entrenar el modelo de machine learning.
```{r}
rf_workflow_reg <- workflow() %>% 
  add_recipe(indicadores_gen_rec) %>% 
  add_model(indicadores_gen_rf)

rf_workflow_reg
```

## Calibración de parámetros

Para calibrar los parametros se utiliza el metodo de validación cruzada. Este procedimiento tiene como proposito encontrar los parametros optimos del modelo o algoritmo.
```{r}
# creación de los folds
indicadores_gen_cv <- vfold_cv(indicadores_gen_train, v=5)
indicadores_gen_cv
```

Ahora se configuran las metricas que se utilizarán para calibrar los parametros del modelo en la validación cruzada. Primero se define la grilla de valores para los parametros del modelo.
```{r}
rf_gird_reg <- expand.grid(mtry = c(3, 4, 5, 7),
                           trees = c(100, 300, 500))

rf_gird_reg
```

Ahora se corre un modelo de random forest para cada una de estas condiciones.
```{r}
rf_tune_results_reg <- rf_workflow_reg %>% 
  tune_grid(resamples = indicadores_gen_cv,
            grid = rf_gird_reg,
            metrics = metric_set(rmse, mae))

rf_tune_results_reg
```

A continuación se presenta la tabla que contiene el valor de las metricas para valor de los parametros y de acuerdo a cada metrica.
```{r}
# print results
rf_metrics_reg <- rf_tune_results_reg %>% 
  collect_metrics()

rf_metrics_reg
```
A continuación se presentan un conjunto de gráfica que permiten analizar el comportamiento de las métricas para cada uno de los paramétros del modelo.
```{r}
rf_metrics_reg %>% 
  filter(.metric == "rmse") %>% 
  ggplot(aes(mtry, mean, col = factor(trees))) +
  geom_line(alpha = 0.5, size = 1) +
  ggtitle("RMSE en función del mtry y el número de árboles")
```
```{r}
rf_metrics_reg %>% 
  filter(.metric == "mae") %>% 
  ggplot(aes(mtry, mean, col = factor(trees))) +
  geom_line(alpha = 0.5, size = 1) +
  ggtitle("RMSE en función del mtry y el número de árboles")
```
A continuación se presenta el codigo para seleccionar los mejores parametros del modelo en función de la métrica rmse:
```{r}
param_final_reg <- rf_tune_results_reg %>% 
  select_best(metric = "rmse")

param_final_reg
```

## Validación del modelo final

En primer lugar se agregan los parametros calibrado al flujo de trabajo.
```{r}
rf_workflow_reg <- rf_workflow_reg %>% 
  finalize_workflow(param_final_reg)

rf_workflow_reg
```
Ahora se valida con los conjuntos de entrenamiento y prueba. En este caso se toma todo el conjunto de entrenamiento y se construye un modelo con los parametros calibrados del random forest.
```{r}
rf_fit_reg <- rf_workflow_reg %>% 
  last_fit(indicadores_gen_split)

rf_fit_reg
```

Ahora se evalua el rmse con el conjunto de entrenamiento en el modelo final.
```{r}
test_perfomance_reg <- rf_fit_reg %>% collect_metrics()

test_perfomance_reg
```

Comparar los valores reales con las predicciones
```{r}
test_predictions_reg <- rf_fit_reg %>% 
  collect_predictions()

test_predictions_reg
```
Grafico con las predicciones
```{r}
ggplot(test_predictions_reg, aes(perc_contr_directa_num, .pred)) +
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("Valor real (contratación directa) Vs predicción (.pred)")
```
## Modelo final
```{r}
final_model <- fit(rf_workflow_reg, indicadores_gen)
final_model
```
## variables de mayor importancia
```{r}
ranger_obj <- pull_workflow_fit(final_model)$fit

rf_importacia_reg <- tibble(variable = names(ranger_obj$variable.importance),
                            importancia = ranger_obj$variable.importance)

rf_importacia_reg

importantes <- data.frame(rf_importacia_reg %>% 
                             mutate(variable = forcats::fct_reorder(variable, importancia)) %>% 
                            arrange(desc(importancia)))

```

Gráfico de las variables más importantes
```{r}
rf_importacia_reg %>% 
  mutate(variable = forcats::fct_reorder(variable, importancia)) %>% 
   top_n(20) %>% 
  ggplot(aes(variable, importancia)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Importancia de los predictores") +
  coord_flip()
 
```

