---
title: "Random Forest"
author: "Yilber Alejandro Erazo Bolaños"
date: "11/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
librería
```{r}
#install.packages("ranger")
#install.packages("tidymodels")
library(tidymodels)
library(knitr)
library(readxl)
library(ggplot2)

# Para poder aplicar el step_smote que hace un especia de upsampling
#install.packages("themis")
library(themis)


library(data.table)
library(readr)

library(vip)
library(recipes)

#install.packages("embed")
library(embed)

# Libraries para feature selection
#install.packages("Boruta")
library(Boruta)
#install.packages("mlbench")
library(mlbench)
#install.packages("caret")
library(caret)
#install.packages("randomForest")
library(randomForest)
```

# Random Forest por regresión

## Preprocesamiento de los datos

Lectura de los datos
```{r}
#supersalud <- read_excel("supersalud_indicadores.xlsx")
indicadores_gen <- read.csv("indicadores_BD.csv")

```

Eliminar columnas que no son necesarias
```{r}
indicadores_gen$X <- NULL
indicadores_gen$cod_entidad <- NULL #porque hay muy pccos datos de cada municipio
indicadores_gen$nit_entidad <- NULL
indicadores_gen$cod_departamento <- NULL #porque ya se tiene el ombre del departamento
indicadores_gen$municipio_entidad <- NULL #porque hay muy pocos datos de cada municipio
indicadores_gen$depto_mun <- NULL #porque hay muy pocos datos de cada municipio
indicadores_gen$perc_contr_direct_val <- NULL #porque no tenemos información sobre la contratación directa

#para volver a correr el modelo porque con esta columna genera error 
indicadores_gen$nombre_entidad <- NULL

#pasar a factor las nominales a ver si funciona el modelo
#indicadores_gen$nombre_entidad <- as.factor(indicadores_gen$nombre_entidad)
indicadores_gen$orden_entidad <- as.factor(indicadores_gen$orden_entidad)
indicadores_gen$departamento_entidad <- as.factor(indicadores_gen$departamento_entidad)

# eliminar la columna de los deptos porque no es importante 
#indicadores_gen$departamento_entidad <- NULL
# cuando se elimina los departamentos el r cuadrado baja


# ver si el modelo hace un mejor trabajo solo con los que tienen contr directa >0
#indicadores_gen <- indicadores_gen %>% filter(perc_contr_directa_num>0)
```

División de los datos en train y test
```{r}
set.seed(123)
indicadores_gen_split <- initial_split(indicadores_gen, 
                                       strata = perc_contr_directa_num,
                                       prop = 4/5)
indicadores_gen_train <- training(indicadores_gen_split)
indicadores_gen_test <- testing(indicadores_gen_split)
```

Procesamiento y preparación de variables
```{r}
indicadores_gen_rec <- recipe(perc_contr_directa_num ~ ., data = indicadores_gen) %>% 
  #update_role(nombre_entidad, new_role = "ID") %>% 
  step_normalize(all_numeric(), -perc_contr_directa_num) %>% 
  step_dummy(all_nominal(), one_hot = TRUE)

#indicadores_gen_rec
```

El objeto 'indicadores_gen_rec' es una rutina de preprocesamiento que se puede aplicar a los datos de train y test.
```{r}
indicadores_gen_train_prep <- indicadores_gen_rec %>% 
  prep(indicadores_gen_train) %>% 
  juice()

#head(indicadores_gen_train_prep)
```

## Configurar el modelo

La librería a usar es 'Parsnip'que ofrece una interfaz unificada para la gran variedad de modelos de machine learning que existen en R. Esto significa que solo tiene que utilizar una forma estandar para configurar un modelo, y puede usar esta configuración diferentes tipos de modelos: Módelo Lineal, Ridge, Lasso, Random Forest, Regresión Logística, Arboles, Support Vector Machine, entre otros.
```{r}
indicadores_gen_rf <- rand_forest() %>% 
  set_args(mtry = tune(),
           trees = tune()) %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("regression")

indicadores_gen_rf %>% translate()
```
## Definir el workflow

El flujo de trabajo permite integrar todas las tareas que se estan desarrollando para entrenar el modelo de machine learning.
```{r}
rf_workflow_reg <- workflow() %>% 
  add_recipe(indicadores_gen_rec) %>% 
  add_model(indicadores_gen_rf)

#rf_workflow_reg
```

## Calibración de parámetros

Para calibrar los parametros se utiliza el metodo de validación cruzada. Este procedimiento tiene como proposito encontrar los parametros optimos del modelo o algoritmo.
```{r}
# creación de los folds
indicadores_gen_cv <- vfold_cv(indicadores_gen_train,
                               v=5)
indicadores_gen_cv
```

Ahora se configuran las metricas que se utilizarán para calibrar los parametros del modelo en la validación cruzada. Primero se define la grilla de valores para los parametros del modelo.
```{r}
rf_gird_reg <- expand.grid(mtry = c(3, 4, 5, 7),
                           trees = c(100, 300, 500))

```

Ahora se corre un modelo de random forest para cada una de estas condiciones.
```{r}
rf_tune_results_reg <- rf_workflow_reg %>% 
  tune_grid(resamples = indicadores_gen_cv,
            grid = rf_gird_reg,
            metrics = metric_set(rmse, mae))

#rf_tune_results_reg
```

A continuación se presenta la tabla que contiene el valor de las metricas para valor de los parametros y de acuerdo a cada metrica.
```{r}
# print results
rf_metrics_reg <- rf_tune_results_reg %>% 
  collect_metrics()

rf_metrics_reg
```
A continuación se presentan un conjunto de gráfica que permiten analizar el comportamiento de las métricas para cada uno de los paramétros del modelo.
```{r}
rf_metrics_reg %>% 
  filter(.metric == "rmse") %>% 
  ggplot(aes(mtry, mean, col = factor(trees))) +
  geom_line(alpha = 0.5, size = 1) +
  ggtitle("RMSE en función del mtry y el número de árboles")
```

grafico2
```{r}
rf_metrics_reg %>% 
  filter(.metric == "mae") %>% 
  ggplot(aes(mtry, mean, col = factor(trees))) +
  geom_line(alpha = 0.5, size = 1) +
  ggtitle("RMSE en función del mtry y el número de árboles")
```

A continuación se presenta el codigo para seleccionar los mejores parametros del modelo en función de la métrica rmse:
```{r}
param_final_reg <- rf_tune_results_reg %>% 
  select_best(metric = "rmse")

param_final_reg
```

## Validación del modelo final

En primer lugar se agregan los parametros calibrado al flujo de trabajo.
```{r}
rf_workflow_reg <- rf_workflow_reg %>% 
  finalize_workflow(param_final_reg)

rf_workflow_reg
```

Ahora se valida con los conjuntos de entrenamiento y prueba. En este caso se toma todo el conjunto de entrenamiento y se construye un modelo con los parametros calibrados del random forest.
```{r}
rf_fit_reg <- rf_workflow_reg %>% 
  last_fit(indicadores_gen_split)

rf_fit_reg
```

Ahora se evalua el rmse con el conjunto de entrenamiento en el modelo final.
```{r}
test_perfomance_reg <- rf_fit_reg %>% collect_metrics()

test_perfomance_reg
```

Comparar los valores reales con las predicciones
```{r}
test_predictions_reg <- rf_fit_reg %>% 
  collect_predictions()

test_predictions_reg
```

Grafico con las predicciones
```{r}
ggplot(test_predictions_reg, aes(perc_contr_directa_num, .pred)) +
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("Valor real (contratación directa) Vs predicción (.pred) TRAIN")

cor.test(test_predictions_reg$perc_contr_directa_num, test_predictions_reg$.pred)
```
## Modelo final
```{r}
final_model <- fit(rf_workflow_reg, indicadores_gen)
final_model
```

## variables de mayor importancia
```{r}
ranger_obj <- pull_workflow_fit(final_model)$fit

rf_importacia_reg <- tibble(variable = names(ranger_obj$variable.importance),
                            importancia = ranger_obj$variable.importance)


importantes <- data.frame(rf_importacia_reg %>% 
                             mutate(variable = forcats::fct_reorder(variable, importancia)) %>% 
                            arrange(desc(importancia)))
#importantes
```

Gráfico de las variables más importantes
```{r}
rf_importacia_reg %>% 
  mutate(variable = forcats::fct_reorder(variable, importancia)) %>% 
   top_n(20) %>% 
  ggplot(aes(variable, importancia)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Importancia de los predictores") +
  coord_flip()

```

NOTA: Cuando se trata de los que SI tuvieron contratación directa el indicador de riesgo de corrupción sigue siendo el segundo más importante pero su valor de importancia se reduce a la mitad.

## Predecir 
```{r}
predicciones <- predict(final_model, new_data = indicadores_gen_test)

#preguntar por esta parte
predicciones <- cbind(predicciones, indicadores_gen_test$perc_contr_directa_num)
names(predicciones) <- c(".pred", "perc_contr_directa_num")
```

## Gráfico del test
```{r}
ggplot(predicciones, aes(perc_contr_directa_num, .pred)) +
  geom_point() + 
  geom_abline(intercept = 0, slope = 1) +
  ggtitle("Valor real (contratación directa) Vs predicción (.pred) TEST")

cor.test(predicciones$perc_contr_directa_num, predicciones$.pred)
```


# Random Forest por clasificación

## Preprocesamiento de los datos

Lectura de los datos
```{r}
#indicadores_clas <- read.csv("indicadores_BD.csv")
#indicadores_bd_td <- indicadores_reserva
#indicadores_bd_td$supers_ind10_oportunidad_entrega_reporte_info_hos <- as.numeric(indicadores_bd_td$supers_ind10_oportunidad_entrega_reporte_info_hos)

indicadores_clas <- indicadores_bd_td
head(indicadores_clas)


#DEJAR TODOS LOS INDICADORES FINANCIEROS !!!
```

Columnas que no se tienen en cuenta

```{r}
variables_no_necesarias <- c(
  "nombre_entidad",
  "cod_entidad",
  "cod_departamento",
  "nit_entidad",
  "municipio_entidad",
  "depto_mun"
)

variables_info_directa <- c(
  # Indicadores iniciales
 "indba_perc_cerrada_num_hos" ,
 "indba_perc_cerrada_val_hos",
 "indba_perc_direc_val_hos",
  # Fin de año (finyr)
  "indba_contr_finyr_directa_dto",
  "indba_prop_contr_finyr_dto",
  "indba_contr_finyr_directa_hos",
  "indba_prop_contr_finyr_hos" )
```


Eliminar columnas que no son necesarias y crear columna riesgo

```{r}
# eliminar las no necesarias
indicadores_clas <- indicadores_clas %>%
  dplyr::select(-all_of(variables_no_necesarias), -all_of(variables_info_directa))

#crear los rangos
indicadores_clas <- indicadores_clas %>% 
  mutate(riesgo = case_when(indba_perc_cdirec_num_hos <= 25 ~ "Bajo o moderado",
                            indba_perc_cdirec_num_hos <= 55 ~ "Medio",
                            TRUE ~ "Alto"))
```

Calcular los cuartiles y graficar

```{r}
#Ccalcular los cuartiles
#cartiles <-quantile(indicadores_clas$indba_perc_cdirec_num)


# hacer histograma con la distribucion de los cuartiles
ggplot(indicadores_clas, aes(indba_perc_cdirec_num_hos)) + 
  geom_histogram(col = "white", fill = "gray", aes(y = ..density..)) + 
  geom_density(col = "blue") + 
  geom_vline(xintercept = cartiles[2], color = "red") +
  geom_vline(xintercept = cartiles[3], color = "red") +
  geom_vline(xintercept = cartiles[4], color = "red") + 
  geom_vline(xintercept = cartiles[5], color = "red") +
  scale_x_continuous(breaks = seq(0,100,10)) +
  labs(title = "Distribución de porcentaje de contratación directa",
       x = "Porcentaje de contratación directa",
       y = "Densidad") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))
```


Eliminar el porcentaje de contratacion directa

```{r}
indicadores_clas$indba_perc_cdirec_num_hos <- NULL

#indicadores_clas$indba_contr_finyr_directa_dto <- NULL
#indicadores_clas$indba_contr_finyr_directa_hos <- NULL
#indicadores_clas$indba_contr_finyr_hos <- NULL
#indicadores_clas$indba_prop_contr_finyr_hos <- NULL
#indicadores_clas$indba_prop_contr_finyr_dto <- NULL

#indicdores_clas$supers_ind10_oportunidad_entrega_reporte_info[is.na(indicadores_clas$supers_ind10_oportunidad_entraega_reporte_info)] <- "NO REGISTRA"

indicadores_clas <- indicadores_clas %>% 
  mutate_if(is.character, factor)

#head(indicadores_clas[,182:184], 10)

#indicadores_clas <- indicadores_clas[,c(1:18, 184)]



```


## Imputación de los Na

Crear los datos de muestra

```{r}
# crear una muestra de los datos
muestra_indicadores_clas <- initial_split(indicadores_clas, strata = riesgo)
muestra_indicadores_clas <- training(muestra_indicadores_clas)

head(muestra_indicadores_clas)
```

Aplicar cambio de Nas en el recipe

```{r}
indicadores_clas_rec_na <- recipe(riesgo ~ ., muestra_indicadores_clas) %>% 
  step_medianimpute(all_numeric()) %>% 
  step_nzv(all_predictors()) %>% 
  prep()
```


Una vez que se ha definido el objeto recipe, con la función prep() se aprenden las transformaciones con los datos de entrenamiento y se aplican a los dos conjuntos con bake().

```{r}
# Se aplican las transformaciones al conjunto de datos
indicadores_clas <- bake(indicadores_clas_rec_na, new_data = indicadores_clas)

#glimpse(datos_train_prep)

apply(is.na(indicadores_clas), 2, cantyprop_nas)
```


## Feature selection

```{r}
# Feature Selection
set.seed(111)
boruta <- Boruta(riesgo ~ ., data = indicadores_clas, doTrace = 2, maxRuns = 500)
print(boruta)
plot(boruta, las = 2, cex.axis = 0.7)
plotImpHistory(boruta)

# Tentative Fix
bor <- TentativeRoughFix(boruta)
print(bor)
attStats(boruta)

#get variable
not_rejected <- getNonRejectedFormula(boruta)
confirmed <- getConfirmedFormula(boruta)
```


División de los datos en train y test

```{r}
set.seed(458)
indicadores_clas_split <- initial_split(indicadores_clas,
                                        strata = riesgo)
indicadores_clas_train <- training(indicadores_clas_split)
indicadores_clas_test <- testing(indicadores_clas_split)
```

Definir las tareas de preprocesamiento

- Normalizar las variables numéricas
-  Crear variables dummyes con las variables categóricas

```{r}
indicadores_clas_rec <- recipe(not_rejected, data = indicadores_clas) %>% 
  step_normalize(all_numeric()) %>% 
  step_other(departamento_entidad) %>% 
  step_dummy(all_nominal(), -riesgo, one_hot = TRUE) %>% 
  step_zv(all_numeric()) %>% #creates a specification of a recipe step that will remove variables that contain only a single value.
 step_smote(riesgo)

prop.table(table(indicadores_clas$riesgo))

#indicadores_clas_rec %>% prep() %>% bake(new_data =  NULL) %>% count(riesgo)
```


## Definir el modelo random forest

Se configura un modelo con los parametros que trae la función por defecto.
```{r}
rf_model_clas <-  rand_forest(mtry = tune(),
                              trees = 1000, #porque este parámeto por lo general no ayuda mucho tunearlo
                              min_n = tune()) %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("classification") 
```

## Definir el workflow

```{r}
rf_workflow_clasific <- workflow() %>% 
  add_recipe(indicadores_clas_rec) %>% 
  add_model(rf_model_clas)
```

## Tunear los parámetros del modelo Random Forest

Crear un regular_grid

```{r}
rf_grid <- grid_regular(
  mtry(range = c(10, 30)),
  min_n(range = c(2, 8)),
  levels = 5
)

rf_grid
```

validación cruada

```{r}
set.seed(245)
rf_folds <- vfold_cv(indicadores_clas_train, strata = riesgo)

clas_metrics <- metric_set(roc_auc, accuracy)

doParallel::registerDoParallel()
set.seed(467)

clas_tune <- rf_workflow_clasific %>% 
  tune_grid(resamples = rf_folds,
            grid = rf_grid,
            metrics = clas_metrics)

clas_tune
```

## Escoger los mejores parámetros

```{r}
rf_best_auc <- select_best(clas_tune, metric = "roc_auc")
rf_best_auc
```

Finalizar el workflow con las metricas (parámetros) tuneados

```{r}
rf_final_model_clas <- finalize_model(rf_model_clas, rf_best_auc)
rf_final_model_clas
```

Hacer el workflow final, que contiene los parámetros tuneados

```{r}
final_workflow_clas <- workflow() %>% 
  add_recipe(indicadores_clas_rec) %>% 
  add_model(rf_final_model_clas)
```


## Validar el modelo de random forest

```{r}
rf_val_clas <- final_workflow_clas %>% 
  last_fit(indicadores_clas_split)

rf_val_clas %>% collect_predictions()
```

## Matriz de confusion
```{r}
rf_val_clas %>% collect_predictions() %>% conf_mat(riesgo, .pred_class)
```

Algunas métricas a partir de la matriz de confusión y otra información de la predicción.

- accuracy: indica en que proporción se predicen bien las dos clases.
- Sensitivity: indica que proporción de las predicciones positivas son correctas, con respecto al total de clases reales positivas.
- Specificity: indica que proporción de las predicciones negativas son correctas, con respecto al total de clases reales negativas.
- Positive predictive: indica que proporción de las predicciones positivas son correctas, con respecto al total de predicciones.
- Negative predictive: indica que proporción de las prediccion negativas son correctas, con respecto al total de predicciones.

```{r}
# Métricas generales como el auc y accuracy
rf_val_clas %>% collect_metrics()
```

```{r}
# Sensibilidad
rf_val_clas %>% collect_predictions() %>% sensitivity(riesgo, .pred_class)
```

```{r}
# Especificidad
rf_val_clas %>% collect_predictions() %>% specificity(riesgo, .pred_class)
```

positiva
```{r}
# Predicción positiva
rf_val_clas %>% collect_predictions() %>% ppv(riesgo, .pred_class)
```

negativa
```{r}
# Predicción negativa
rf_val_clas %>% collect_predictions() %>% npv(riesgo, .pred_class)
```

A continuación se presenta el número de obervaciones que fueron correctamente clasificadas y el núermo que fue incorrectamente clasificadas
```{r}
#Correcto
rf_val_clas %>% collect_predictions() %>% 
  mutate(correcto = case_when(.pred_class == riesgo ~ "Yes",
                              TRUE ~ "No")) %>% 
  filter(correcto == "Yes") %>%
  count()

# incorrecto
rf_val_clas %>% collect_predictions() %>% 
  mutate(correcto = case_when(.pred_class == riesgo ~ "Yes",
                              TRUE ~ "No")) %>% 
  filter(correcto == "No") %>%
  count()
```

## Modelo final del random forest
```{r}
rf_final_model_clas <- fit(final_workflow_clas, training(indicadores_clas_split))
rf_final_model_clas
```


testing

```{r}
rf_final_model_clas_test <- fit(final_workflow_clas, testing(indicadores_clas_split))
rf_final_model_clas_test
```


## variables de mayor importancia
```{r}
ranger_obj_clas <- pull_workflow_fit(rf_final_model_clas)$fit

rf_importacia_clas <- tibble(variable = names(ranger_obj_clas$variable.importance),
                            importancia = ranger_obj_clas$variable.importance)


importantes_clas <- data.frame(rf_importacia_clas %>% 
                             mutate(variable = forcats::fct_reorder(variable, importancia)) %>% 
                            arrange(desc(importancia)))

importantes_clas

```
## Accuracy

```{r}
# Nivel de accuracy
rf_metric <- rf_val_clas %>% collect_metrics() %>% mutate(model = "Random Forest")
rf_metric
```

Gráfico de las variables más importantes
```{r}
importantes_clas %>% 
  mutate(variable = forcats::fct_reorder(variable, importancia)) %>% 
   top_n(20) %>% 
  ggplot(aes(variable, importancia)) + 
  geom_bar(stat = "identity") + 
  ggtitle("Importancia de los predictores") +
  coord_flip()
```

## Gráfico con los importantes por subcategoría

Hacer un gráfico mostrando la suma total de la importancia de las categorías de los indicadores que se tuvieron en cuenta.
```{r}
# Total
separate(data = importantes_clas,
         col = variable,
         into = "inicio",
         sep = "_") %>% 
  group_by(inicio) %>% 
  summarise(valor = sum(importancia)) %>% 
  ggplot() +
    geom_bar(aes(x = reorder(inicio, valor), y = valor ) ,stat = "identity") +
    coord_flip() +
    labs(x = "Subcategoría de indicador",
         y = "Importancia",
         title = "Importancia total de las subcategorías") +
    theme(plot.title = element_text(hjust = 0.5))

# Promedio
separate(data = importantes_clas,
         col = variable,
         into = "inicio",
         sep = "_") %>% 
  group_by(inicio) %>% 
  summarise(valor = mean(importancia)) %>% 
  ggplot() +
    geom_bar(aes(x = reorder(inicio, valor), y = valor ) ,stat = "identity") +
    coord_flip() +
    labs(x = "Subcategoría de indicador",
         y = "Importancia",
         title = "Importancia media de las subcategorías")+
    theme(plot.title = element_text(hjust = 0.5))
    
```

Seleccionar si es por hospital, municipio o departamento

```{r}
#str_extract_all(importantes_clas$variable, "dto, mun, hos", simplify = FALSE, boundary("word"))
importantes_clas$fin <- str_sub(importantes_clas$variable, -3, -1)
```

Seleccionar

```{r}
# Suma total
importantes_clas %>% filter(fin == "hos" | fin == "mun" | fin == "dto") %>% 
  group_by(fin) %>% 
  summarise(total = sum(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = reorder(fin, total), y = total), stat = "identity") +
      coord_flip() +
      labs(x = "Nivel del indicador",
           y = "Importancia",
           title = "Importancia total de los niveles")+
      theme(plot.title = element_text(hjust = 0.5))

# Suma media
importantes_clas %>% filter(fin == "hos" | fin == "mun" | fin == "dto") %>% 
  group_by(fin) %>% 
  summarise(total = mean(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = reorder(fin, total), y = total), stat = "identity") +
      coord_flip() +
      labs(x = "Nivel del indicador",
           y = "Importancia",
           title = "Importancia media de los niveles")+
      theme(plot.title = element_text(hjust = 0.5))
```


ver si hay nas

```{r}
sapply(indicadores_bd_td, function(x) sum(is.na(x)))
```

