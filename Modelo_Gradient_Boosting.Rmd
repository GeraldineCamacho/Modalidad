---
title: "Gradient Boosting"
author: "Yilber Alejandro Erazo Bolaños"
date: "17/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Boosting es otra estrategia de ensemble que se puede emplear con un amplio grupo de métodos de statistical learning, entre ellos los árboles de decisión. La idea detrás del boosting es ajustar, de forma secuencial, múltiples weak learners (modelos sencillos que predicen solo ligeramente mejor que lo esperado por azar). Cada nuevo modelo emplea información del modelo anterior para aprender de sus errores, mejorando iteración a iteración. En el caso de los árboles de predicción, un weak learners se consigue utilizando árboles con muy pocas ramificaciones. A diferencia del método de bagging (random forest), el boosting no hace uso de muestreo repetido (bootstrapping), la diferencia entre los árboles que forman el ensemble se origina por que la importancia (peso) de las observaciones va cambiando en cada iteración.

librerías

```{r}
# Tratamiento de datos
# ==============================================================================
library(MASS)
library(dplyr)
library(tidyr)
library(skimr)

# Gráficos
# ==============================================================================
library(ggplot2)
#install.packages("ggpubr")
library(ggpubr)

# Preprocesado y modelado
# ==============================================================================
library(tidymodels)
#install.packages("xgboost")
library(xgboost)
#install.packages("gbm")
library(gbm)
#install.packages("doParallel")
library(doParallel)
```


# Gradient Boosting por regresión

## Preprocesamiento de los datos

Lectura de los datos
```{r}
#supersalud <- read_excel("supersalud_indicadores.xlsx")
indicadores_gen <- read.csv("indicadores_BD.csv")
```

Eliminar columnas que no son necesarias
```{r}
indicadores_gen$X <- NULL
indicadores_gen$cod_entidad <- NULL #porque hay muy pccos datos de cada municipio
indicadores_gen$nit_entidad <- NULL
indicadores_gen$cod_departamento <- NULL #porque ya se tiene el ombre del departamento
indicadores_gen$municipio_entidad <- NULL #porque hay muy pocos datos de cada municipio
indicadores_gen$depto_mun <- NULL #porque hay muy pocos datos de cada municipio
indicadores_gen$perc_contr_direct_val <- NULL #porque no tenemos información sobre la contratación directa

#para volver a correr el modelo porque con esta columna genera error 
indicadores_gen$nombre_entidad <- NULL

#pasar a factor las nominales a ver si funciona el modelo
#indicadores_gen$nombre_entidad <- as.factor(indicadores_gen$nombre_entidad)
indicadores_gen$orden_entidad <- as.factor(indicadores_gen$orden_entidad)
indicadores_gen$departamento_entidad <- as.factor(indicadores_gen$departamento_entidad)

# eliminar la columna de los deptos porque no es importante 
#indicadores_gen$departamento_entidad <- NULL
# cuando se elimina los departamentos el r cuadrado baja


# ver si el modelo hace un mejor trabajo solo con los que tienen contr directa >0
#indicadores_gen <- indicadores_gen %>% filter(perc_contr_directa_num>0)
```

División de los datos en train y test
```{r}
set.seed(789)
indicadores_gen_split <- initial_split(indicadores_gen, 
                                       strata = perc_contr_directa_num,
                                       prop = 4/5)
datos_train <- training(indicadores_gen_split)
datos_test <- testing(indicadores_gen_split)
```

Los modelos de XGBoost pueden trabajar con varios formatos de datos, entre ellos las matrices de R. Sin embargo, es recomendable utilizar xgb.DMatrix, una estructura propia y optimizada esta librería.
```{r}
#datos_train <- xgb.DMatrix(
#  data = indicadores_gen_train %>% 
#    dplyr::select(-perc_contr_directa_num) %>% data.matrix(),
#  label = indicadores_gen_train$perc_contr_directa_num)

#datos_test <- xgb.DMatrix(
#  data = indicadores_gen_test %>%
#    dplyr::select(-perc_contr_directa_num) %>% data.matrix(),
#  label = indicadores_gen_test$perc_contr_directa_num)
```

## Definición del modelo y de los hiperparámetros a optimizar
```{r}
modelo_xgb <- boost_tree(mode        = "regression",
                         mtry        = tune(),
                         trees       = tune(),
                         tree_depth  = tune(),
                         learn_rate  = tune(),
                         sample_size = tune(),
                         stop_iter   = NULL) %>% 
  set_engine(engine = "xgboost")

modelo_xgb
```

## Definición del preprocesado

- Normalizar las variables numéricas
-  Crear variables dummyes con las variables categóricas
```{r}
transformer <- recipe(formula= perc_contr_directa_num ~ .,
                      data = datos_train) %>% 
  #update_role(nombre_entidad, new_role = "ID") %>% 
  step_normalize(all_numeric(), -perc_contr_directa_num) %>% 
  step_dummy(all_nominal(), one_hot = TRUE) %>% 
  prep()

#transformer <- prep(transformer, verbose = TRUE)
```

## Definición de las estrategia de validación y creación de particiones - Definición de parámetros
```{r}
set.seed(1234)
cv_folds <- vfold_cv(data = datos_train,
                     v = 5,
                     strata = perc_contr_directa_num)
```

## Definir el workflow
```{r}
workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo_xgb)
```

## Grid de hiperparámetros
```{r}
hiperpar_grid <- expand_grid("trees" = c(100, 500, 1000),
                             "mtry" = c(ceiling(sqrt(ncol(datos_train))), ncol(datos_train)-1),
                             "tree_depth" = c(1, 3, 10, 20),
                             "learn_rate" = c(0.01, 0.1, 0.3),
                             "sample_size" = c(0.5, 1))
```

## Optimización de hiperparámetros ejecución
```{r}
cl <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl)

set.seed(1235)
grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(rmse),
              grid      = hiperpar_grid
            )

stopCluster(cl)

```

## Mejores hiperparámetros
```{r}
show_best(grid_fit, metric = "rmse", n = 1)

mejores_hiperpar <- select_best(grid_fit, metric = "rmse")

```

## Entrenamiento final
```{r}
modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = datos_train
                    ) %>%
                    pull_workflow_fit()

modelo_final_fit
```

## Error de test del modelado final
```{r}
# aplicar los mismos pasos al test data
transformer_test <- recipe(formula= perc_contr_directa_num ~ .,
                      data = datos_test) %>% 
  #update_role(nombre_entidad, new_role = "ID") %>% 
  step_normalize(all_numeric(), -perc_contr_directa_num) %>% 
  step_dummy(all_nominal(), one_hot = TRUE) %>% 
  prep()


predicciones_xgb <- modelo_final_fit %>% 
  predict(new_data = transformer_test,
          type = "numeric")


predicciones_xgb <- modelo_final_fit %>% 
  predict(new_data = bake(transformer, datos_test %>% dplyr::select(-perc_contr_directa_num)),
          type = "numeric")

predicciones_xgb <- predicciones_xgb %>% 
  bind_cols(datos_test %>% dplyr::select(perc_contr_directa_num))

rmse_test <- rmse(data = predicciones_xgb,
                  truth = perc_contr_directa_num,
                  estimate = .pred,
                  na_rm = TRUE)

rmse_test
```

## Importancia de los predictores

La función xgb.importance() calcula la importancia de los predictores de un modelo XGBoost en base a la pureza de nodos.
```{r}
importance_matrix <- xgb.importance(model = modelo_final_fit$fit)
xgb.plot.importance(importance_matrix = importance_matrix)
```




# Gradient Boosting por clasificación 

## Preprocesamiento de los datos

Lectura de los datos

```{r}
indicadores_gen <- indicadores_clas
head(indicadores_gen)
```

LA IMPUTACIÓN Y LA REDUCCIÓN DE VARIABLES ESTÁ EN EL CÓDIGO DE RANDOM FOREST

División de los datos en train y test

```{r}
set.seed(789)
vb_split <- initial_split(indicadores_gen, 
                          strata = riesgo)
vb_train <- training(vb_split)
vb_test <- testing(vb_split)
```

Un modelo XGBoost se basa en árboles, por lo que no se necesita hacer mucho preprocesamiento de los datos; no hay que preocuparse por los factores o centrar o escalar los datos. Esto quiere decir que no se requiere de un recipe, si no que se va directamente a configurar la especificación de modelo.Vamos a ajustar muchos hiperparámetros del modelo.

```{r}
xgb_spec <- boost_tree(
  trees = 1000, 
  tree_depth = tune(),
  min_n = tune(), 
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(),
  mtry = tune(),         ## randomness
  learn_rate = tune(),                         ## step size
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

xgb_spec
```

Usemos un diseño que llene el espacio para que podamos cubrir el espacio del hiperparámetro lo mejor posible, hay 2 formas de hacerlo, con grid_max_entropy() y con grid_latin_hypercube(). Existe la copción de usar grid_regular() y un expand_grid() para tunear los hiperparámetros, pero por términos computacionales es mejor determinar un espacio para cubrir el espacio de cada hiperparámetro. 

```{r}
xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), vb_train),
  learn_rate(),
  size = 30
)

xgb_grid
```


Definir las tareas de preprocesamiento

- Normalizar las variables numéricas
-  Crear variables dummyes con las variables categóricas

```{r}
indicadores_gen_rec <- recipe(riesgo ~ ., data = indicadores_gen) %>% 
  step_normalize(all_numeric()) %>% 
  step_other(departamento_entidad) %>% 
  step_dummy(all_nominal(), -riesgo, one_hot = TRUE) %>% 
  step_zv(all_numeric()) %>%
  step_smote(riesgo)

indicadores_gen_rec %>% prep() %>% bake(new_data =  NULL) %>% count(riesgo)
```


Pongamos la especificación del modelo en un flujo de trabajo para mayor comodidad. Como no tenemos ningún preprocesamiento de datos complicado, podemos usar add_formula () como nuestro preprocesador de datos.

```{r}
xgb_wf <- workflow() %>%
  add_recipe(indicadores_gen_rec) %>% 
#  add_formula(not_rejected) %>% 
  add_model(xgb_spec)

xgb_wf
```

Ahora se crea una validación cruzada para tunear el modelo.

```{r}
set.seed(125)
vb_folds <- vfold_cv(vb_train, strata = riesgo)

vb_folds
```

ES HORA DE TUNEAR. Usamos tune_grid() con nuestro flujo de trabajo ajustable, nuestros remuestreos y nuestra cuadrícula de parámetros para probar. Usemos control_grid (save_pred = TRUE) para que podamos explorar las predicciones después.

```{r}
doParallel::registerDoParallel()

set.seed(234)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = vb_folds,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE)
)

xgb_res
```

Explorar resultados:
Podemos explorar las métricas de todos estos modelos.

```{r}
collect_metrics(xgb_res)
```

También podemos utilizar la visualización para comprender nuestros resultados.

```{r}
xgb_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  dplyr::select(mean, mtry:sample_size) %>%
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")
```

Recuerde que usamos un diseño que llena el espacio para que los parámetros prueben. Parece que los valores más altos para la profundidad del árbol fueron mejores, pero aparte de eso, lo principal que saco de este gráfico es que hay varias combinaciones de parámetros que funcionan bien.

¿Cuáles son los conjuntos de parámetros con mejor rendimiento?

```{r}
show_best(xgb_res, "roc_auc")
```

Puede que haya muchos parámetros, pero pudimos obtener un buen rendimiento con varias combinaciones diferentes. Elijamos el mejor.
```{r}
best_auc <- select_best(xgb_res, "roc_auc")
best_auc

xgb_res %>% collect_metrics() %>%
  filter(.metric == "accuracy") %>%  arrange(desc(mean))
```

Ahora finalicemos nuestro flujo de trabajo optimizable con estos valores de parámetros
```{r}
final_xgb <- finalize_workflow(
  xgb_wf,
  best_auc
)

final_xgb
```


¡Es hora de volver al conjunto de pruebas! Usemos last_fit () para ajustar nuestro modelo una última vez a los datos de entrenamiento y evaluar nuestro modelo una última vez en el conjunto de pruebas. Tenga en cuenta que esta es la primera vez que utilizamos los datos de prueba durante todo este análisis de modelado.

```{r}
final_res <- last_fit(final_xgb, vb_split)

collect_metrics(final_res)
```

Matriz de conflicto
```{r}
final_res %>% 
  collect_predictions() %>% 
  conf_mat(riesgo, .pred_class)
```

Curva roc

```{r}
XGB_Curva_ROC_indba <- final_res %>% 
  collect_predictions() %>%
  rename(".pred_Bajo_o_moderado" = ".pred_Bajo o moderado") %>% 
  roc_curve(riesgo, c(.pred_Alto, .pred_Bajo_o_moderado, .pred_Medio)) %>%
  autoplot() +
  labs(title = "Curva ROC por nivel de riesgo",
       subtitle = "Gradient Boosting") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))

XGB_Curva_ROC_indba
```


Guardar la imagen

```{r}
ggsave("XGB_Curva_ROC_indba.png", 
       XGB_Curva_ROC_indba)
```

## Importancia de las variable

```{r}
#install.packages("vip")
#library(vip)

XGB_importancia_variables_indba <- final_xgb %>%
  fit(data = vb_train) %>%
  pull_workflow_fit() %>%
  vip(geom = "col",
      num_features = 20L) + 
    labs( title = "Importancia de las variables",
        x = "Variable",
        y = "Importancia") +
#  coord_flip() +
  theme(plot.title = element_text(hjust = 0.5))

XGB_importancia_variables_indba
```
Guardar imagen

```{r}
ggsave("XGB_importancia_variables_indba.png",
       XGB_importancia_variables_indba)
```

## Importancia de las subcategorías

```{r}
importantes_xgb <- final_xgb %>%
  fit(data = vb_train) %>%
  pull_workflow_fit() %>%
  vip::vi() %>%
  rename("variable" = "Variable",
         "importancia"= "Importance")
```

Gráfico

```{r}
# Total
XGB_Importancia_subcategorias_total_indba<- separate(data = importantes_xgb,
         col = variable,
         into = "inicio",
         sep = "_") %>% 
  group_by(inicio) %>% 
  summarise(valor = sum(importancia)) %>% 
  ggplot() +
    geom_bar(aes(x = reorder(inicio, valor), y = valor ) ,stat = "identity") +
    coord_flip() +
    labs(x = "Subcategoría de indicador",
         y = "Importancia",
         title = "Importancia total de las subcategorías") +
    theme(plot.title = element_text(hjust = 0.5))


#Promedio
XGB_Importancia_subcategorias_media_indba <- separate(data = importantes_xgb,
         col = variable,
         into = "inicio",
         sep = "_") %>% 
  group_by(inicio) %>% 
  summarise(valor = mean(importancia)) %>% 
  ggplot() +
    geom_bar(aes(x = reorder(inicio, valor), y = valor ) ,stat = "identity") +
    coord_flip() +
    labs(x = "Subcategoría de indicador",
         y = "Importancia",
         title = "Importancia media de las subcategorías") +
    theme(plot.title = element_text(hjust = 0.5))

XGB_Importancia_subcategorias_total_indba
XGB_Importancia_subcategorias_media_indba
```


Guadar imagenes

```{r}
# Total
ggsave("XGB_Importancia_subcategorias_total_indba.png",
       XGB_Importancia_subcategorias_total_indba)

# Media
ggsave("XGB_Importancia_subcategorias_media_indba.png",
       XGB_Importancia_subcategorias_media_indba)
```


Seleccionar si es por hospital, municipio o departamento

```{r}
#str_extract_all(importantes_clas$variable, "dto, mun, hos", simplify = FALSE, boundary("word"))
importantes_xgb$fin <- str_sub(importantes_xgb$variable, -3, -1)
```

Seleccionar

```{r}
# Suma total
XGB_Importancia_niveles_total_sin_boruta <- importantes_xgb %>%
  filter(fin == "hos" | fin == "mun" | fin == "dto") %>% 
  group_by(fin) %>% 
  summarise(total = sum(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = reorder(fin, total), y = total), stat = "identity") +
      coord_flip() +
      labs(x = "Nivel del indicador",
           y = "Importancia",
           title = "Importancia total de los niveles")+
      theme(plot.title = element_text(hjust = 0.5))

# Suma media
XGB_Importancia_niveles_media_sin_boruta <- importantes_xgb %>%
  filter(fin == "hos" | fin == "mun" | fin == "dto") %>% 
  group_by(fin) %>% 
  summarise(total = mean(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = reorder(fin, total), y = total), stat = "identity") +
      coord_flip() +
      labs(x = "Nivel del indicador",
           y = "Importancia",
           title = "Importancia media de los niveles")+
      theme(plot.title = element_text(hjust = 0.5))

XGB_Importancia_niveles_total_sin_boruta
XGB_Importancia_niveles_media_sin_boruta
```

Guardar las imagenes

```{r}
# Total
ggsave("XGB_Importancia_niveles_total_sin_boruta.png",
       XGB_Importancia_niveles_total_sin_boruta)

# Media
ggsave("XGB_Importancia_niveles_media_sin_boruta.png",
       XGB_Importancia_niveles_media_sin_boruta)
```

Importancia por cada año del que se tienen datos (si la variable no se dividió por años entonces no se tiene en cuenta)

```{r}
# importancia total de los años
XGB_Importancia_años_total_indba <- importantes_xgb %>% 
  mutate(variable = gsub("_1_", "un", variable),
         variable = gsub("IC4K", "ICFK", variable),
         variable = gsub("_5_", "_cinco_", variable),
         variable = gsub("ind2", "ind_dos", variable),
         variable = gsub("_42_", "_cuarentaydos_", variable),
         variable = gsub("ind10", "ind_diez", variable),
         variable = gsub("_X0", "", variable),
         variable = gsub("_X1", "", variable),
         annio = parse_number(variable),
         annio = as.character(annio)) %>%
  mutate_if(is.character, funs(replace_na(., "Sin año"))) %>% 
  group_by(annio) %>% 
  summarise(importancia_annio = sum(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = fct_reorder(annio, importancia_annio), y = importancia_annio), stat = "identity") +
      coord_flip() +
      labs(x = "Año del indicador",
           y = "Importancia",
           title = "Importancia total de los años")+
      theme(plot.title = element_text(hjust = 0.5))

# Importancia media de los años
XGB_Importancia_años_media_indba <- importantes_xgb %>% 
  mutate(variable = gsub("_1_", "un", variable),
         variable = gsub("IC4K", "ICFK", variable),
         variable = gsub("_5_", "_cinco_", variable),
         variable = gsub("ind2", "ind_dos", variable),
         variable = gsub("_42_", "_cuarentaydos_", variable),
         variable = gsub("ind10", "ind_diez", variable),
         variable = gsub("_X0", "", variable),
         variable = gsub("_X1", "", variable),
         annio = parse_number(variable),
         annio = as.character(annio)) %>%
  mutate_if(is.character, funs(replace_na(., "Sin año"))) %>% 
  group_by(annio) %>% 
  summarise(importancia_annio = mean(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = fct_reorder(annio, importancia_annio), y = importancia_annio), stat = "identity") +
      coord_flip() +
      labs(x = "Año del indicador",
           y = "Importancia",
           title = "Importancia media de los años")+
      theme(plot.title = element_text(hjust = 0.5))

XGB_Importancia_años_total_indba
XGB_Importancia_años_media_indba
```

Guardar imagen 

```{r}
#Total
ggsave("XGB_Importancia_años_total_indba.png",
       XGB_Importancia_años_total_indba)

#Media
ggsave("XGB_Importancia_años_media_indba.png",
       XGB_Importancia_años_media_indba)
```

## Hacer pca y umap para agrupar

Datos

```{r}
indicadores_gen_varfin_indba <- indicadores_gen %>% 
  dplyr::select(departamento_entidad,
                names(indicadores_clas_rec %>%
                        prep() %>%
                        bake(new_data =  NULL) %>%
                        dplyr::select(-c(departamento_entidad_Antioquia,
                                         departamento_entidad_Boyacá,
                                         departamento_entidad_Cundinamarca,
                                         departamento_entidad_Nariño,
                                         departamento_entidad_Santander,
                                         departamento_entidad_Tolima,
                                         departamento_entidad_Valle.del.Cauca,
                                         departamento_entidad_other)
                                      )
                      )
                ) %>% 
  merge(indicadores_bd_td %>% dplyr::select(nombre_entidad, indba_ptr_valora_total_hos))# %>% 
#  dplyr::select(-departamento_entidad)
#mutate(departamento_entidad = case_when(departamento_entidad != c("Antioquia", "Boyacá", "Cundinamarca", "Nariño", "Santander", "Tolima", "Valle del Cauca") ~ "Other",
#                                          TRUE ~ as.character(departamento_entidad))) #%>% count(departamento_entidad)
#sapply(indicadores_clas_varfin, function(x) sum(is.na(x)))
```

### PCA

```{r}
pca_xgboost_rec_indba <- recipe(riesgo ~ ., data = indicadores_gen_varfin_indba) %>%
  update_role(nombre_entidad, departamento_entidad, new_role = "id") %>%
  step_dummy(all_nominal(), - c(nombre_entidad, departamento_entidad),one_hot = TRUE) %>% 
  step_normalize(all_predictors()) %>%
  step_pca(all_predictors())

pca_xgboost_prep_indba <- prep(pca_xgboost_rec_indba)

pca_xgboost_prep_indba
```

Ver los factores 

```{r}
tidy(pca_xgboost_prep, 3)
```

Ver los datos

```{r}
juice(pca_xgboost_prep)
```

Gráfico

```{r}
XGB_PCA_hospitales_indba <- juice(pca_xgboost_prep_indba) %>%
  ggplot(aes(PC1, PC2, label = departamento_entidad)) +
  geom_point(aes(color = departamento_entidad), alpha = 0.7, size = 2, show.legend = FALSE) +
  geom_text(check_overlap = TRUE, hjust = "inward", family = "IBMPlexSans") +
  labs(color = NULL,
       title = "PCA de hospitales por departamentos") +
  theme(plot.title = element_text(hjust = 0.5))

XGB_PCA_hospitales_indba
```

Guardar imagen

```{r}
#Sin leyenda
ggsave("XGB_PCA_hospitales_indba_sin_leyenda.png",
       XGB_PCA_hospitales_indba)

#Con leyenda
ggsave(
  "XGB_PCA_hospitales_indba_con_leyenda.png",
  juice(pca_xgboost_prep_indba) %>%
  ggplot(aes(PC1, PC2, label = departamento_entidad)) +
  geom_point(aes(color = departamento_entidad), alpha = 0.7, size = 2) +
  geom_text(check_overlap = TRUE, hjust = "inward", family = "IBMPlexSans") +
  labs(color = NULL,
       title = "PCA de hospitales por departamentos") +
  theme(plot.title = element_text(hjust = 0.5))
)
```


### UMAP

```{r}
umap_xgboost_rec_indba <- recipe(riesgo ~ ., data = indicadores_gen_varfin_indba) %>%
  update_role(nombre_entidad, departamento_entidad, new_role = "id") %>%
  step_dummy(all_nominal(), - c(nombre_entidad, departamento_entidad), one_hot = TRUE) %>% 
  step_normalize(all_predictors()) %>%
  step_umap(all_predictors())

umap_xgboost_prep_indba <- prep(umap_xgboost_rec_indba)

umap_xgboost_prep_indba
```

Ver los factores 

```{r}
tidy(umap_xgb_prep, 3)
```

Ver los datos

```{r}
juice(umap_xgb_prep)
```

Gráfico

```{r}
XGB_UMAP_hospitales_indba <- juice(umap_xgboost_prep_indba) %>%
  ggplot(aes(umap_1, umap_2, label = departamento_entidad)) +
  geom_point(aes(color = departamento_entidad), alpha = 0.7, size = 2,  show.legend = FALSE) +
  geom_text(check_overlap = TRUE, hjust = "inward", family = "IBMPlexSans") +
  labs(color = NULL,
       title = "UMAP de hospitales por departamentos") +
  theme(plot.title = element_text(hjust = 0.5))

XGB_UMAP_hospitales_indba
```

Guardar imagenes

```{r}
#sin leyenda
ggsave("XGB_UMAP_indba_sin_leyenda.png",
       XGB_UMAP_hospitales_indba)

#con leyenda
ggsave(
  "XGB_UMAP_indba_con_leyenda.png",
juice(umap_xgboost_prep_indba) %>%
  ggplot(aes(umap_1, umap_2, label = departamento_entidad)) +
  geom_point(aes(color = departamento_entidad), alpha = 0.7, size = 2) +
  geom_text(check_overlap = TRUE, hjust = "inward", family = "IBMPlexSans") +
  labs(color = NULL,
       title = "UMAP de hospitales por departamentos") +
  theme(plot.title = element_text(hjust = 0.5))  
)
```
faltan gráficos de dependencia parcial



ver si hay nas

```{r}
sapply(indicadores_gen, function(x) sum(is.na(x)))
```
