---
title: "Gradient Boosting"
author: "Yilber Alejandro Erazo Bolaños"
date: "17/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Boosting es otra estrategia de ensemble que se puede emplear con un amplio grupo de métodos de statistical learning, entre ellos los árboles de decisión. La idea detrás del boosting es ajustar, de forma secuencial, múltiples weak learners (modelos sencillos que predicen solo ligeramente mejor que lo esperado por azar). Cada nuevo modelo emplea información del modelo anterior para aprender de sus errores, mejorando iteración a iteración. En el caso de los árboles de predicción, un weak learners se consigue utilizando árboles con muy pocas ramificaciones. A diferencia del método de bagging (random forest), el boosting no hace uso de muestreo repetido (bootstrapping), la diferencia entre los árboles que forman el ensemble se origina por que la importancia (peso) de las observaciones va cambiando en cada iteración.

librerías
```{r}
# Tratamiento de datos
# ==============================================================================
library(MASS)
library(dplyr)
library(tidyr)
library(skimr)

# Gráficos
# ==============================================================================
library(ggplot2)
#install.packages("ggpubr")
library(ggpubr)

# Preprocesado y modelado
# ==============================================================================
library(tidymodels)
#install.packages("xgboost")
library(xgboost)
#install.packages("gbm")
library(gbm)
#install.packages("doParallel")
library(doParallel)
```


# Gradient Boosting por regresión

## Preprocesamiento de los datos

Lectura de los datos
```{r}
#supersalud <- read_excel("supersalud_indicadores.xlsx")
indicadores_gen <- read.csv("indicadores_BD.csv")
```

Eliminar columnas que no son necesarias
```{r}
indicadores_gen$X <- NULL
indicadores_gen$cod_entidad <- NULL #porque hay muy pccos datos de cada municipio
indicadores_gen$nit_entidad <- NULL
indicadores_gen$cod_departamento <- NULL #porque ya se tiene el ombre del departamento
indicadores_gen$municipio_entidad <- NULL #porque hay muy pocos datos de cada municipio
indicadores_gen$depto_mun <- NULL #porque hay muy pocos datos de cada municipio
indicadores_gen$perc_contr_direct_val <- NULL #porque no tenemos información sobre la contratación directa

#para volver a correr el modelo porque con esta columna genera error 
indicadores_gen$nombre_entidad <- NULL

#pasar a factor las nominales a ver si funciona el modelo
#indicadores_gen$nombre_entidad <- as.factor(indicadores_gen$nombre_entidad)
indicadores_gen$orden_entidad <- as.factor(indicadores_gen$orden_entidad)
indicadores_gen$departamento_entidad <- as.factor(indicadores_gen$departamento_entidad)

# eliminar la columna de los deptos porque no es importante 
#indicadores_gen$departamento_entidad <- NULL
# cuando se elimina los departamentos el r cuadrado baja


# ver si el modelo hace un mejor trabajo solo con los que tienen contr directa >0
#indicadores_gen <- indicadores_gen %>% filter(perc_contr_directa_num>0)
```

División de los datos en train y test
```{r}
set.seed(789)
indicadores_gen_split <- initial_split(indicadores_gen, 
                                       strata = perc_contr_directa_num,
                                       prop = 4/5)
datos_train <- training(indicadores_gen_split)
datos_test <- testing(indicadores_gen_split)
```

Los modelos de XGBoost pueden trabajar con varios formatos de datos, entre ellos las matrices de R. Sin embargo, es recomendable utilizar xgb.DMatrix, una estructura propia y optimizada esta librería.
```{r}
#datos_train <- xgb.DMatrix(
#  data = indicadores_gen_train %>% 
#    dplyr::select(-perc_contr_directa_num) %>% data.matrix(),
#  label = indicadores_gen_train$perc_contr_directa_num)

#datos_test <- xgb.DMatrix(
#  data = indicadores_gen_test %>%
#    dplyr::select(-perc_contr_directa_num) %>% data.matrix(),
#  label = indicadores_gen_test$perc_contr_directa_num)
```

## Definición del modelo y de los hiperparámetros a optimizar
```{r}
modelo_xgb <- boost_tree(mode        = "regression",
                         mtry        = tune(),
                         trees       = tune(),
                         tree_depth  = tune(),
                         learn_rate  = tune(),
                         sample_size = tune(),
                         stop_iter   = NULL) %>% 
  set_engine(engine = "xgboost")

modelo_xgb
```

## Definición del preprocesado

- Normalizar las variables numéricas
-  Crear variables dummyes con las variables categóricas
```{r}
transformer <- recipe(formula= perc_contr_directa_num ~ .,
                      data = datos_train) %>% 
  #update_role(nombre_entidad, new_role = "ID") %>% 
  step_normalize(all_numeric(), -perc_contr_directa_num) %>% 
  step_dummy(all_nominal(), one_hot = TRUE) %>% 
  prep()

#transformer <- prep(transformer, verbose = TRUE)
```

## Definición de las estrategia de validación y creación de particiones - Definición de parámetros
```{r}
set.seed(1234)
cv_folds <- vfold_cv(data = datos_train,
                     v = 5,
                     strata = perc_contr_directa_num)
```

## Definir el workflow
```{r}
workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo_xgb)
```

## Grid de hiperparámetros
```{r}
hiperpar_grid <- expand_grid("trees" = c(100, 500, 1000),
                             "mtry" = c(ceiling(sqrt(ncol(datos_train))), ncol(datos_train)-1),
                             "tree_depth" = c(1, 3, 10, 20),
                             "learn_rate" = c(0.01, 0.1, 0.3),
                             "sample_size" = c(0.5, 1))
```

# Optimización de hiperparámetros ejecución
```{r}
cl <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl)

set.seed(1235)
grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(rmse),
              grid      = hiperpar_grid
            )

stopCluster(cl)

```

## Mejores hiperparámetros
```{r}
show_best(grid_fit, metric = "rmse", n = 1)

mejores_hiperpar <- select_best(grid_fit, metric = "rmse")

```

## Entrenamiento final
```{r}
modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = datos_train
                    ) %>%
                    pull_workflow_fit()

modelo_final_fit
```

## Error de test del modelado final
```{r}
# aplicar los mismos pasos al test data
transformer_test <- recipe(formula= perc_contr_directa_num ~ .,
                      data = datos_test) %>% 
  #update_role(nombre_entidad, new_role = "ID") %>% 
  step_normalize(all_numeric(), -perc_contr_directa_num) %>% 
  step_dummy(all_nominal(), one_hot = TRUE) %>% 
  prep()


predicciones_xgb <- modelo_final_fit %>% 
  predict(new_data = transformer_test,
          type = "numeric")


predicciones_xgb <- modelo_final_fit %>% 
  predict(new_data = bake(transformer, datos_test %>% dplyr::select(-perc_contr_directa_num)),
          type = "numeric")

predicciones_xgb <- predicciones_xgb %>% 
  bind_cols(datos_test %>% dplyr::select(perc_contr_directa_num))

rmse_test <- rmse(data = predicciones_xgb,
                  truth = perc_contr_directa_num,
                  estimate = .pred,
                  na_rm = TRUE)

rmse_test
```

## Importancia de los predictores

La función xgb.importance() calcula la importancia de los predictores de un modelo XGBoost en base a la pureza de nodos.
```{r}
importance_matrix <- xgb.importance(model = modelo_final_fit$fit)
xgb.plot.importance(importance_matrix = importance_matrix)
```



# Gradient Boosting por clasificación 

## Preprocesamiento de los datos

Lectura de los datos
```{r}
indicadores_gen <- indicadores_bd_td
head(indicadores_gen)
```

Columnas que no se tienen en cuenta

```{r}
variables_no_necesarias <- c(
  "nombre_entidad",
  "cod_entidad",
  "cod_departamento",
  "nit_entidad",
  "municipio_entidad",
  "depto_mun"
)

variables_info_directa <- c(
  # Indicadores iniciales
 "indba_perc_cerrada_num_hos" ,
 "indba_perc_cerrada_val_hos",
 "indba_perc_direc_val_hos",
  # Fin de año (finyr)
  "indba_contr_finyr_directa_dto",
  "indba_prop_contr_finyr_dto",
  "indba_contr_finyr_directa_hos",
  "indba_prop_contr_finyr_hos" )
```


Eliminar columnas que no son necesarias y crear columna riesgo

```{r}
# eliminar las no necesarias
indicadores_gen <- indicadores_gen %>%
  dplyr::select(-all_of(variables_no_necesarias), -all_of(variables_info_directa))

#crear los rangos
indicadores_gen <- indicadores_gen %>% 
  mutate(riesgo = case_when(indba_perc_cdirec_num_hos <= 25 ~ "Bajo o moderado",
                            indba_perc_cdirec_num_hos <= 55 ~ "Medio",
                            TRUE ~ "Alto"))
```

Calcular los cuartiles y graficar

```{r}
#Ccalcular los cuartiles
#cartiles <-quantile(indicadores_gen$indba_perc_cdirec_num)


# hacer histograma con la distribucion de los cuartiles
ggplot(indicadores_gen, aes(indba_perc_cdirec_num_hos)) + 
  geom_histogram(col = "white", fill = "gray", aes(y = ..density..)) + 
  geom_density(col = "blue") + 
  geom_vline(xintercept = cartiles[2], color = "red") +
  geom_vline(xintercept = cartiles[3], color = "red") +
  geom_vline(xintercept = cartiles[4], color = "red") + 
  geom_vline(xintercept = cartiles[5], color = "red") +
  scale_x_continuous(breaks = seq(0,100,10)) +
  labs(title = "Distribución de porcentaje de contratación directa",
       x = "Porcentaje de contratación directa",
       y = "Densidad") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5))
```

Eliminar el porcentaje de contratacion directa

```{r}
indicadores_gen$indba_perc_cdirec_num_hos <- NULL

#indicadores_gen$indba_contr_finyr_directa_dto <- NULL
#indicadores_gen$indba_contr_finyr_directa_hos <- NULL
#indicadores_gen$indba_contr_finyr_hos <- NULL
#indicadores_gen$indba_prop_contr_finyr_hos <- NULL
#indicadores_gen$indba_prop_contr_finyr_dto <- NULL

#indicdores_clas$supers_ind10_oportunidad_entrega_reporte_info[is.na(indicadores_gen$supers_ind10_oportunidad_entraega_reporte_info)] <- "NO REGISTRA"

indicadores_gen <- indicadores_gen %>% 
  mutate_if(is.character, factor)

#head(indicadores_gen[,182:184], 10)

#indicadores_gen <- indicadores_gen[,c(1:18, 184)]
```


## Imputación de los Na

Crear los datos de muestra

```{r}
# crear una muestra de los datos
muestra_indicadores_gen <- sample(2, nrow(indicadores_gen), replace = TRUE, prob = c(0.6, 0.4))
muestra_indicadores_gen <- indicadores_gen[ind == 1]

head(muestra_indicadores_gen)
```

Aplicar cambio de Nas en el recipe

```{r}
indicadores_gen_rec_na <- recipe(riesgo ~ ., muestra_indicadores_gen) %>% 
  step_medianimpute(all_numeric()) %>% 
  step_nzv(all_predictors()) %>% 
  prep()
```


Una vez que se ha definido el objeto recipe, con la función prep() se aprenden las transformaciones con los datos de entrenamiento y se aplican a los dos conjuntos con bake().

```{r}
# Se aplican las transformaciones al conjunto de datos
indicadores_gen <- bake(indicadores_gen_rec_na, new_data = indicadores_gen)

#glimpse(datos_train_prep)

apply(is.na(indicadores_gen), 2, cantyprop_nas)
```


## Feature selection

```{r}
# Feature Selection
set.seed(111)
boruta <- Boruta(riesgo ~ ., data = indicadores_gen, doTrace = 2, maxRuns = 500)
print(boruta)
plot(boruta, las = 2, cex.axis = 0.7)
plotImpHistory(boruta)

# Tentative Fix
bor <- TentativeRoughFix(boruta)
print(bor)
attStats(boruta)

#get variable
not_rejected <- getNonRejectedFormula(boruta)
confirmed <- getConfirmedFormula(boruta)
```


División de los datos en train y test

```{r}
set.seed(789)
vb_split <- initial_split(indicadores_gen, 
                          strata = riesgo)
vb_train <- training(vb_split)
vb_test <- testing(vb_split)
```

Un modelo XGBoost se basa en árboles, por lo que no se necesita hacer mucho preprocesamiento de los datos; no hay que preocuparse por los factores o centrar o escalar los datos. Esto quiere decir que no se requiere de un recipe, si no que se va directamente a configurar la especificación de modelo.Vamos a ajustar muchos hiperparámetros del modelo.

```{r}
xgb_spec <- boost_tree(
  trees = 1000, 
  tree_depth = tune(),
  min_n = tune(), 
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(),
  mtry = tune(),         ## randomness
  learn_rate = tune(),                         ## step size
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

xgb_spec
```

Usemos un diseño que llene el espacio para que podamos cubrir el espacio del hiperparámetro lo mejor posible, hay 2 formas de hacerlo, con grid_max_entropy() y con grid_latin_hypercube(). Existe la copción de usar grid_regular() y un expand_grid() para tunear los hiperparámetros, pero por términos computacionales es mejor determinar un espacio para cubrir el espacio de cada hiperparámetro. 

```{r}
xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), vb_train),
  learn_rate(),
  size = 30
)

xgb_grid
```


Definir las tareas de preprocesamiento

- Normalizar las variables numéricas
-  Crear variables dummyes con las variables categóricas

```{r}
indicadores_gen_rec <- recipe(not_rejected,data = indicadores_gen) %>% 
  step_normalize(all_numeric()) %>% 
  step_other(departamento_entidad) %>% 
  step_dummy(all_nominal(), -riesgo, one_hot = TRUE) %>% 
  step_zv(all_numeric()) 
#%>%
#  step_smote(riesgo)

indicadores_gen_rec %>% prep() %>% bake(new_data =  NULL) %>% count(riesgo)
```


Pongamos la especificación del modelo en un flujo de trabajo para mayor comodidad. Como no tenemos ningún preprocesamiento de datos complicado, podemos usar add_formula () como nuestro preprocesador de datos.
```{r}
xgb_wf <- workflow() %>%
#  add_recipe(indicadores_gen_rec) %>% 
  add_formula(not_rejected) %>% 
  add_model(xgb_spec)

xgb_wf
```

Ahora se crea una validación cruzada para tunear el modelo.

```{r}
set.seed(125)
vb_folds <- vfold_cv(vb_train, strata = riesgo)

vb_folds
```

ES HORA DE TUNEAR. Usamos tune_grid() con nuestro flujo de trabajo ajustable, nuestros remuestreos y nuestra cuadrícula de parámetros para probar. Usemos control_grid (save_pred = TRUE) para que podamos explorar las predicciones después.

```{r}
doParallel::registerDoParallel()

set.seed(234)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = vb_folds,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE)
)

xgb_res
```

Explorar resultados:
Podemos explorar las métricas de todos estos modelos.

```{r}
collect_metrics(xgb_res)
```

También podemos utilizar la visualización para comprender nuestros resultados.

```{r}
xgb_res %>%
  collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  dplyr::select(mean, mtry:sample_size) %>%
  pivot_longer(mtry:sample_size,
               values_to = "value",
               names_to = "parameter"
  ) %>%
  ggplot(aes(value, mean, color = parameter)) +
  geom_point(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~parameter, scales = "free_x") +
  labs(x = NULL, y = "AUC")
```
Recuerde que usamos un diseño que llena el espacio para que los parámetros prueben. Parece que los valores más altos para la profundidad del árbol fueron mejores, pero aparte de eso, lo principal que saco de este gráfico es que hay varias combinaciones de parámetros que funcionan bien.

¿Cuáles son los conjuntos de parámetros con mejor rendimiento?
```{r}
show_best(xgb_res, "roc_auc")
```

Puede que haya muchos parámetros, pero pudimos obtener un buen rendimiento con varias combinaciones diferentes. Elijamos el mejor.
```{r}
best_auc <- select_best(xgb_res, "roc_auc")
best_auc

xgb_res %>% collect_metrics() %>%
  filter(.metric == "accuracy") %>%  arrange(desc(mean))
```

Ahora finalicemos nuestro flujo de trabajo optimizable con estos valores de parámetros
```{r}
final_xgb <- finalize_workflow(
  xgb_wf,
  best_auc
)

final_xgb
```


¡Es hora de volver al conjunto de pruebas! Usemos last_fit () para ajustar nuestro modelo una última vez a los datos de entrenamiento y evaluar nuestro modelo una última vez en el conjunto de pruebas. Tenga en cuenta que esta es la primera vez que utilizamos los datos de prueba durante todo este análisis de modelado.

```{r}
final_res <- last_fit(final_xgb, vb_split)

collect_metrics(final_res)
```

Matriz de conflicto
```{r}
final_res %>% 
  collect_predictions() %>% 
  conf_mat(riesgo, .pred_class)
```

## Importancia de las variable

```{r}
#install.packages("vip")
#library(vip)

final_xgb %>%
  fit(data = vb_train) %>%
  pull_workflow_fit() %>%
  vip(geom = "col",
      num_features = 20L)
```


## Importancia de las subcategorías

```{r}
importantes_xgb <- final_xgb %>%
  fit(data = vb_train) %>%
  pull_workflow_fit() %>%
  vip::vi() %>%
  rename("variable" = "Variable",
         "importancia"= "Importance")
```

Gráfico

```{r}
# Total
separate(data = importantes_xgb,
         col = variable,
         into = "inicio",
         sep = "_") %>% 
  group_by(inicio) %>% 
  summarise(valor = sum(importancia)) %>% 
  ggplot() +
    geom_bar(aes(x = reorder(inicio, valor), y = valor ) ,stat = "identity") +
    coord_flip() +
    labs(x = "Subcategoría de indicador",
         y = "Importancia",
         title = "Importancia total de las subcategorías") +
    theme(plot.title = element_text(hjust = 0.5))


#Promedio
separate(data = importantes_xgb,
         col = variable,
         into = "inicio",
         sep = "_") %>% 
  group_by(inicio) %>% 
  summarise(valor = mean(importancia)) %>% 
  ggplot() +
    geom_bar(aes(x = reorder(inicio, valor), y = valor ) ,stat = "identity") +
    coord_flip() +
    labs(x = "Subcategoría de indicador",
         y = "Importancia",
         title = "Importancia media de las subcategorías") +
    theme(plot.title = element_text(hjust = 0.5))
```

Seleccionar si es por hospital, municipio o departamento

```{r}
#str_extract_all(importantes_clas$variable, "dto, mun, hos", simplify = FALSE, boundary("word"))
importantes_xgb$fin <- str_sub(importantes_xgb$variable, -3, -1)
```

Seleccionar

```{r}
# Suma total
importantes_xgb  %>% filter(fin == "hos" | fin == "mun" | fin == "dto") %>% 
  group_by(fin) %>% 
  summarise(total = sum(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = reorder(fin, total), y = total), stat = "identity") +
      coord_flip() +
      labs(x = "Nivel del indicador",
           y = "Importancia",
           title = "Importancia total de los niveles")+
      theme(plot.title = element_text(hjust = 0.5))

# Suma media
importantes_xgb %>% filter(fin == "hos" | fin == "mun" | fin == "dto") %>% 
  group_by(fin) %>% 
  summarise(total = mean(importancia)) %>% 
  ggplot() +
      geom_bar(aes(x = reorder(fin, total), y = total), stat = "identity") +
      coord_flip() +
      labs(x = "Nivel del indicador",
           y = "Importancia",
           title = "Importancia media de los niveles")+
      theme(plot.title = element_text(hjust = 0.5))
```

